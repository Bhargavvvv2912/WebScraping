# Name of the GitHub Action workflow
name: Daily Delhi School Attendance Scraper

on:
  workflow_dispatch:
  schedule:
    # cron format: minute hour day-of-month month day-of-week
    # '30 12 * * *' means it will run at 12:30 PM UTC every day.
    # This corresponds to 6:00 PM in India Standard Time (IST).
    - cron: '30 12 * * *'

# Defines the sequence of jobs to be run for this workflow.
jobs:
  scrape-and-commit:
    # A descriptive name for the job, which will appear in the Actions log.
    name: Scrape Data and Commit CSV
    runs-on: ubuntu-latest
    steps:
      # Step 1: Checks out your repository's code onto the virtual machine.
      # This is necessary so the runner can access your Webscraping.py script.
      - name: Check out repository
        uses: actions/checkout@v3

      # Step 2: Sets up a Python environment for the script to run in.
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' # Specifies the version of Python to use.
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run the web scraper
        run: python Webscraping.py

      - name: Commit and push new data
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Automated: Add latest attendance data"
          commit_user_name: "GitHub Actions Bot"
          commit_user_email: "actions@github.com"
          file_pattern: "data/*.csv"